---
published: true
layout: post
date: '2019-06-25 08:34:00 +0800'
categories: AI
tags:
  - 数据积累
  - 知识图谱
  - 数据处理能力
  - 广度优先
excerpt: 与其说知识图谱的规模从根本上决定了智能的瓶颈，不如说是数据量的积累和数据的处理能力决定了智能的发展。
title: 数据量、数据处理能力与知识图谱
---
<div align="center"><img src="https://www.bobinsun.cn/assets/images/logo-top.jpg"/></div>

---

### 前言 

之前的文章中提到过知识图谱的主要应用方向有三个：语义搜索、智能问答、可视化决策。而底层基础决定上层建筑，底层的基础说来说去还是知识快速查询、图实时计算、以及知识推理，但当下的最大困难是数据的获取与知识的抽取。



知识图谱背后，强大的自然语言处理能力，是不可或缺的，尤其是医药行业，缺少可商业化的实体识别、抽取工具，如果一味的追求高质量的数据或自动化的办法，必然导致在行业发展初期数据量上的滞后性。

---

### 规则模式

考虑到医疗行业的本身的局限性，数据需要保证严谨、合规、科学。因此可靠的数据来源为临床病历、医学指南、医学教科书、相关论文、科普资讯、医患问答。以上数据来源大多都为文献，但是文献有文献的好处，语言描述多为书面语，可以从中总结规律，从而升级为模板进行收取。比如:

```
( 疾病->症状），书面语描述多为：<X疾病>的症状有<Y症状>，<X疾病>的临床表现为<Y症状>，<X疾病>容易引起<Y症状>等不适症状等等。
```


人的书写与口语表达都存在一定的模式，针对这些数据及模式，学习文献中的语法及结构，采用机器学习算法，综合统计自然语言处理，收集足够数量的数据，数据量越大越能体现出规律及语法，从海量文本中学习知识的描述方式，如果想单方面从结构化数据中获取更多的数据，那么数据量将及其有限，产出的知识效果将难以支撑上层应用。与其说知识图谱的规模从根本上决定了智能的瓶颈，不如说是数据量的积累和数据的处理能力决定了智能的发展。



即使是高度结构化的医学病历，其结构中也大多存在着大段的文本，要想抽取其中的疾病症状，也需要强大的自然语言处理能力，所以这块终究是绕不过去的。

---

### 个人建议

基于模板的方式虽然简单粗暴，但是易于利用非结构化文本进行冷启动，数据海量。其实无论采用哪种方式，前期的人工训练、干预都必不可少。虽然此方法计算复杂度较高，但可以提升计算性能，根据抽取效果对规则模式的效果设计打分卡，从而优化算法，提升覆盖率与召回率。



如果最开始就想建立大而全知识图谱，各方面都考虑，必然导致各方面受缚，无法前进。前期选择一个小领域，例如疾病、药品。以深度优先或者广度优先的方式，从海量文本抽取信息。（个人建议采用广度优先，此处的原因与爬虫的工程要点区别不大，是采用深度优先还是广度优先，类比可得出）。

<div align="center"><img src="https://www.bobinsun.cn/assets/images/medical-01.png"/></div> 


> 如果没有聪明的办法，就先想办法把笨办法做到最好。

---

### 公众号

<div align="center"><img src="https://www.bobinsun.cn/assets/images/ercode.png"/></div>
